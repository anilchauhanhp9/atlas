---
title: "Analyze the genecatalog output of metagenome-atlas"
output: html_document
---

```{r, setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, eval = TRUE,
  message = FALSE,
  warning = FALSE,
  cache = FALSE, include = TRUE
)
```



```
BiocManager::install("tidybulk")

```


```{r, libraries,include=FALSE}
# library(plotly) # don't load due to import conflicts
library(heatmaply)
library(dplyr) # dpyr masks select from plotly
library(readr)
library(stringr)
library(tidyr)
library(tibble)
library(ggplot2)
library(ggbeeswarm)
library(pheatmap)
library(grid)
# library(vegan)
library(useful)
library(kableExtra)

library(rhdf5)
library(dplyr)
library(tibble)

library(arrow)
library(yaml)
library(SummarizedExperiment)
```

Atlas output files are stored in the `DiarrheaExample` folder.

```{r, file_paths}

data_dir <- "../DiarrheaExample/"
atlas_version <- "v2.17"

files <- yaml::yaml.load_file("../atlas_output_files.yaml")[[atlas_version]]




for (key1 in names(files)) {
  value1 <- files[[key1]]
  if (is.character(value1)) {
    # It's a direct path
    files[[key1]] <- file.path(data_dir, value1)
  } else if (is.list(value1)) {
    # It's a nested list, go deeper
    for (key2 in names(value1)) {
      value2 <- value1[[key2]]
      files[[key1]][[key2]] <- file.path(data_dir, value2)
    }
  }
}

genecatalog_files <- files[["genecatalog"]]

abundance_file <- genecatalog_files$coverage
```



Load the metadata


```{r metadata}


metadata <- read.csv(file.path(data_dir, "metadata.csv")) %>%
  column_to_rownames("sample_accession")

head(metadata)

group_variable <- "group"
```






# Look at the gene stats

Let's have a look at the dimension of the data
```{r}

# get dimension of data

h5overview <- rhdf5::h5ls(abundance_file)
dim <- h5overview[1, "dim"] %>%
  stringr::str_split(" x ", simplify = T) %>%
  as.numeric()

Ngenes <- dim[1]
Nsamples <- dim[2]

cat("The genecatalog contains", Ngenes, "genes and", Nsamples, "samples.\n")
```

Because the dimesnons of the genecatalog are huge (even more so with more samples) but
many genes are detected only in a subset of samples,
I optimized the datafile to allow for fast loading of a subset of the data.

However we still want information from all the genes.
The file `r genecatalog_files$sample_stats` contains stats per sample of the genecatalog.
Escpecially the number of genes that are detected in each sample and the total coverage which we will use for normalization.

Similarly the file `r gene_catalog_files$gene_stats` contains stats per gene, e.g. the number of samples in which the gene is detected.

Let's first look at the stats per sample.

### Gene stats per sample

```{r}

sample_stats <- read.table(genecatalog_files$sample_stats, sep = "\t", header = T, row.names = 1)

# check that we have expected column names
assertthat::assert_that("Sum_coverage" %in% colnames(sample_stats))


# get copies per million for normalization
total_covarage <- sample_stats[, "Sum_coverage"]
names(total_covarage) <- rownames(sample_stats)

head(sample_stats)
```


```{r}


# Plot the two numeric columns side by side using facet_wrap
df_melt <- sample_stats %>%
  select(all_of(c("Sum_coverage", "Genes_nz_coverage"))) %>%
  rename(c(
    Sum_coverage = "Total coverage",
    Genes_nz_coverage = "N detected genes"
  )) %>%
  reshape2::melt()

ggplot(df_melt, aes(x = variable, y = value)) +
  geom_beeswarm(size = 3, alpha = 0.7, cex = 5) +
  facet_wrap(vars(variable), ncol = 2, scales = "free") +
  labs(x = NULL, y = NULL) +
  theme_minimal()
```


### Stats per gene


```{r}

gene_stats <- arrow::read_parquet(genecatalog_files$coverage_stats)
head(gene_stats)
```

Samples_nz_coverage: Number of samples in which the gene has a non-zero coverage
Samples_nz_counts: Number of samples in which the gene has a non-zero counts
Sum_coverage: Sum of the coverage of the gene in all samples

The values for `Samples_nz_coverage` and `Samples_nz_counts` are not the same
because if there are only a view reads mapped to a gene but less than halve of the gene is covered the median coverage is zero.



```{r}


# Assuming your tibble is named 'gene_stats', and you want to create histograms for the specified columns
ggplot(gene_stats, aes(x = log10(Sum_coverage))) +
  geom_histogram(binwidth = 0.2, fill = "blue", color = "black", alpha = 0.7) +
  labs(
    title = "Histogram of log(Sum_coverage)",
    x = "log(Sum_coverage)",
    y = "Frequency"
  )

ggplot(gene_stats, aes(x = Samples_nz_coverage)) +
  geom_histogram(binwidth = 10, fill = "green", color = "black", alpha = 0.7) +
  labs(
    title = "Histogram of Samples_nz_coverage",
    x = "Samples_nz_coverage",
    y = "Frequency"
  )
```


```{r}
# Load the ggplot2 library if not already loaded
library(ggplot2)

# Create a 2D histogram for log10(Sum_coverage) vs. GC
ggplot(gene_stats, aes(x = GC, y = log10(Sum_coverage))) +
  geom_bin2d(bins = 30, aes(fill = ..density..)) +
  scale_fill_gradient(low = "blue", high = "red") +
  labs(
    title = "2D Histogram: log10(Sum_coverage) vs. GC",
    x = "GC",
    y = "log10(Sum_coverage)"
  )

# Create a 2D histogram for log10(Sum_coverage) vs. Length
ggplot(gene_stats, aes(x = Length, y = log10(Sum_coverage))) +
  geom_bin2d(bins = 30, aes(fill = ..density..)) +
  scale_fill_gradient(low = "blue", high = "red") +
  labs(
    title = "2D Histogram: log10(Sum_coverage) vs. Length",
    x = "Length",
    y = "log10(Sum_coverage)"
  )

# Create a 2D histogram for log10(Sum_coverage) vs. Samples_nz_coverage
ggplot(gene_stats, aes(x = Samples_nz_coverage, y = log10(Sum_coverage))) +
  geom_bin2d(bins = 30, aes(fill = ..density..)) +
  scale_fill_gradient(low = "blue", high = "red") +
  labs(
    title = "2D Histogram: log10(Sum_coverage) vs. Samples_nz_coverage",
    x = "Samples_nz_coverage",
    y = "log10(Sum_coverage)"
  )
```


## Mapping rate

Let's check the fraction of reads that could be mapped to the genecatalog for each sample.

```{r, mapping_rate, fig.width=2.5, fig.height=4}

read_stats <- read_tsv(files[["readcounts"]], show_col_types = FALSE) %>%
  filter(Step == "QC") %>%
  mutate(Total_reads = Reads_pe * 2 + Reads_se) %>%
  .[, c("Sample", "Total_reads", "Reads_pe", "Reads_se")]

read_stats <- read_stats %>%
  left_join(rownames_to_column(sample_stats, "Sample")) %>%
  mutate(Mapping_rate = Total_counts / Total_reads * 100)



# add metadata to read_stats
read_stats <- read_stats
read_stats[, "x"] <- "Genecatalog"



plt <- ggplot(read_stats, aes(
  y = Mapping_rate,
  x = x, text = paste("Sample:", Sample)
)) +
  ylim(c(50, 100)) +
  # xlim(c(-0.1,0.1)) +
  labs(x = NULL) +
  geom_beeswarm(cex = 2, size = 2) +
  theme_minimal()

print(plt)

# ggplotly(plt,tooltip = c('text','y' ))
```

# Load abunance of a subset of genes 

One could load the whole gene catalog like this:


``` R

# Load full genecatalog matrix, 

data <- h5read(abundance_file, "data")

attributes= h5readAttributes(abundance_file, "data")

colnames(data) <- attributes$sample_names

```




but usually only a subset of genes is of interest.
The folowing code allows to load only subset of genes.


I see two ways to subset the genes:

1. Load only genes based on gene stats, e.g. genes that are found in at least 10% of the samples
2. Load only genes that have annotations, e.g. KEGG annotations





```{r}
# Some helper functions to convert between gene names and gene numbers

GeneNr2GeneName <- function(GeneNumbers, MaxGeneNumber = Ngenes) {
  paste0("Gene", formatC(format = "d", GeneNumbers, flag = "0", width = ceiling(log10(MaxGeneNumber))))
}

GeneName2GeneNr <- function(GeneNames) {
  as.integer(str_sub(GeneNames, start = 5))
}


# helper function to load subset of genes from hdf5 file
load_subset_of_genes <- function(abundance_file, indexes_of_genes_to_load) {
  cat("Load ", length(indexes_of_genes_to_load), " genes\n")


  data <- rhdf5::h5read(
    file = abundance_file, name = "data",
    index = list(indexes_of_genes_to_load, NULL)
  )

  # add sample names
  attributes <- rhdf5::h5readAttributes(abundance_file, "data")
  colnames(data) <- attributes$sample_names
  rownames(data) <- GeneNr2GeneName(indexes_of_genes_to_load)

  return(data)
}
```

## 1. Load only genes based on gene stats
Here we load only genes that are found in at least 2 samples.
```{r}


# renmove "Gene" from the gene name to get only the GeneNr
gene_stats["GeneNr"] <- GeneName2GeneNr(gene_stats$GeneName)



# filter genes that are present in at least 10% of the samples
filtered_genes <- gene_stats %>%
  filter(Samples_nz_coverage > 0.1 * Nsamples) %>%
  dplyr::pull(GeneNr)


# take a subset to speed up caluclation !!!! remove this line
filtered_genes <- filtered_genes[1:1000]


cat("Select", length(filtered_genes), " genes.\n")



gene_coverage <- load_subset_of_genes(abundance_file, filtered_genes)
gene_coverage[1:5, 1:5]
```

Lets calculate the shannon diversity of the genes. 
```{r}
shannon_diversity <- vegan::diversity(t(gene_coverage), index = "shannon")

hist(shannon_diversity)
```


## Normalisation


Normalze gene counts to **gene counts per million**, which is analogous to transcripts per million.

Alternative ways to normalze would be to normalize to single copy genes. 
Example the one from [MuSiCC](https://github.com/borenstein-lab/MUSiCC/blob/master/musicc/data/uscg_76_kegg_min_2313.lst)

MUSiCC: A marker genes based framework for metagenomic normalization and accurate profiling of gene abundances in the microbiome. Ohad Manor and Elhanan Borenstein. Genome Biology

```{r }


gene_gcpm <- gene_coverage %*% diag(1 / total_covarage[colnames(gene_coverage)]) * 1e6
colnames(gene_gcpm) <- colnames(gene_coverage)

gene_gcpm[1:5, 1:5]
```


```{r }
# Save the normalized data as tsv.gz file
write_delim(as.data.frame(gene_gcpm),
  file.path(data_dir, "Genecatalog", "Filtered_genes_cpm.tsv.gz"),
  delim = "\t"
)
```


## 2. Load only genes with annotations


```{r }


annotations <- read_parquet(genecatalog_files$kegg)
annotations["GeneName"] <- GeneNr2GeneName(annotations$GeneNr)

# take a subset to speed up caluclation !!!! remove this line
annotations <- annotations[1:1000, ]

gene_nrs_with_annotations <- annotations %>%
  pull("GeneNr") %>%
  unique()


data <- load_subset_of_genes(abundance_file, gene_nrs_with_annotations)


data[1:10, 1:5]
```


```{r }
# Normalize

annoated_genes_gcpm <- data %*% diag(1 / total_covarage[colnames(data)]) * 1e6
colnames(annoated_genes_gcpm) <- colnames(data)

annoated_genes_gcpm[1:5, 1:5]
```

As genes can have multiple annotations we need to create a matrix with genes as rows and annotations as columns.
```{r }

# a matrix with gene rn x ko_id

annotation_matrix <- annotations[c("GeneName", "ko_id")] %>%
  mutate(Present = 1) %>%
  pivot_wider(
    names_from = ko_id,
    values_from = Present,
    # values_fn = list(Present = sum), # if you want to take into acount multiple mapping
    values_fill = 0
  ) %>%
  column_to_rownames("GeneName") %>%
  as.matrix() %>%
  t()




annotation_matrix[1:5, 1:5]

cat(" Genes have max ", max(rowSums(annotation_matrix)), " annotations.\n")
```

Now let's multiply the gene coverage with the annotation matrix to get the abundance per annotation.
**If a gene has multiple annotations the abundance is counted for *each* annotation.**
```{r }

# make shure the data aligns
assertthat::assert_that(all(colnames(annotation_matrix) == rownames(annoated_genes_gcpm)))

# multiply gene coverage with annotation matrix,
annoation_cpm <- annotation_matrix %*% annoated_genes_gcpm

annoation_cpm[1:5, 1:5]
```




```{r }
# Save the normalized data as tsv.gz file
write_delim(as.data.frame(annoation_cpm),
  file.path(data_dir, "Genecatalog", "Kegg_cpm.tsv.gz"),
  delim = "\t"
)
```


```{r }


# take the log10 of the data
log_annoation_cpm <- log10(annoation_cpm + 1)

# create a heatmap
heatmap(log_annoation_cpm,
  col = colorRampPalette(c("white", "blue"))(100),
  margins = c(10, 10),
  main = "Data in annotations [log10(cmp+1)]"
)
```




# Integrate them in a SummarizedExperiment object

```{r }


rownames(annotations) <- NULL

SE <- SummarizedExperiment(
  assays = list(gcpm = data),
  colData = metadata[colnames(data), ],
  rowData = annotations
)
```


```{}
library(tidybulk)
```




